{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"../input/chiu-2015/2015_BOE_Chiu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(torch.nn.Module):\n",
    "    \n",
    "    \n",
    "    def downBlock(self, in_channels, out_channels, kernel_size = 3):\n",
    "        block = torch.nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, kernel_size),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    torch.nn.BatchNorm2d(out_channels),\n",
    "                                    torch.nn.Conv2d(out_channels, out_channels, kernel_size),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    torch.nn.BatchNorm2d(out_channels))\n",
    "        return block\n",
    "    def upBlock(self,in_channels, mid_channels,out_channels, kernel_size):\n",
    "        block = torch.nn.Sequential(torch.nn.Conv2d(in_channels, mid_channels, kernel_size),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    torch.nn.BatchNorm2d(mid_channels),\n",
    "                                    torch.nn.Conv2d(mid_channels, mid_channels, kernel_size),\n",
    "                                    torch.nn.ReLU(),\n",
    "                                    torch.nn.BatchNorm2d(mid_channels),\n",
    "                                    torch.nn.ConvTranspose2d(mid_channels, out_channels, kernel_size = 3, stride = 2, padding = 1, output_padding = 1))\n",
    "        return block\n",
    "    \n",
    "    def finalBlock(self,in_channels, mid_channels, out_channels, kernel_size):\n",
    "        block = torch.nn.Sequential(torch.nn.Conv2d(in_channels, mid_channels, kernel_size),\n",
    "                                   torch.nn.ReLU(),\n",
    "                                   torch.nn.BatchNorm2d(mid_channels),\n",
    "                                   torch.nn.Conv2d(mid_channels, mid_channels, kernel_size), \n",
    "                                   torch.nn.ReLU(),\n",
    "                                   torch.nn.BatchNorm2d(mid_channels),\n",
    "                                   torch.nn.Conv2d(mid_channels, out_channels, kernel_size, padding = 1),\n",
    "                                   torch.nn.ReLU(),\n",
    "                                   torch.nn.BatchNorm2d(out_channels))\n",
    "        return block\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Unet, self).__init__()\n",
    "        \n",
    "        #Encoder\n",
    "        self.encode1 = self.downBlock(in_channels, out_channels = 64, kernel_size = 3)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size = 2)\n",
    "        self.encode2 = self.downBlock(64, 128, 3)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size = 2)\n",
    "        self.encode3 = self.downBlock(128, 256, 3)        \n",
    "        self.maxpool3 = torch.nn.MaxPool2d(kernel_size = 2)\n",
    "        \n",
    "        #bottleneck layer\n",
    "        \n",
    "        self.bottleneck = torch.nn.Sequential(torch.nn.Conv2d(256,512,3),\n",
    "                                             torch.nn.ReLU(),\n",
    "                                             torch.nn.BatchNorm2d(512),\n",
    "                                             torch.nn.Conv2d(512,512,3),\n",
    "                                             torch.nn.ReLU(),\n",
    "                                             torch.nn.BatchNorm2d(512),\n",
    "                                             torch.nn.ConvTranspose2d(512,256, kernel_size = 3, stride = 2, padding = 1, output_padding = 1 ))\n",
    "        self.decode3 = self.upBlock(512,256,128,3)\n",
    "        self.decode2 = self.upBlock(256, 128, 64, 3)\n",
    "        self.finalLayer = self.finalBlock(128, 64, out_channels, 3)\n",
    "        \n",
    "    def copy_concat(self, upsampled, bypass, crop=False):\n",
    "        if crop:\n",
    "            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
    "            bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #encoder\n",
    "        encodeBlock1 = self.encode1(x)\n",
    "        encodePool1 = self.maxpool1(encodeBlock1)\n",
    "        encodeBlock2 = self.encode2(encodePool1)\n",
    "        encodePool2 = self.maxpool2(encodeBlock2)\n",
    "        encodeBlock3 = self.encode3(encodePool2)\n",
    "        encodePool3 = self.maxpool3(encodeBlock3)\n",
    "        \n",
    "        #bottleneck\n",
    "        \n",
    "        bottleneck1 = self.bottleneck(encodePool3)\n",
    "        \n",
    "        #decoder\n",
    "        \n",
    "        cat3 = self.copy_concat(bottleneck1, encodeBlock3, True)\n",
    "        decodeBlock3 = self.decode3(cat3)\n",
    "        cat2 = self.copy_concat(decodeBlock3, encodeBlock2, True)\n",
    "        decodeBlock2 = self.decode2(cat2)\n",
    "        cat1 = self.copy_concat(decodeBlock2, encodeBlock1, True)\n",
    "        finalBlock = self.finalLayer(cat1)\n",
    "        return finalBlock\n",
    "\n",
    "        \n",
    "unet = Unet(in_channels=1,out_channels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../input/chiu-2015/2015_BOE_Chiu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = [os.path.join(path, 'Subject_0{}.mat'.format(i)) for i in range(1,10)] + [os.path.join(path, 'Subject_10.mat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 284\n",
    "HEIGHT = 284\n",
    "WIDTHOUT = 196\n",
    "HEIGHTOUT = 196\n",
    "indices = [i for i in range(5,55, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = loadmat(dataPath[0])\n",
    "img_tensor = mat['images']\n",
    "manual_fluid_tensor = mat['manualFluid1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = np.transpose(img_tensor, (2, 0, 1))\n",
    "manual_fluid_array = np.transpose(manual_fluid_tensor, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.resize(img_array, (61, 250,250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(manual_fluid_array[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(x):\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "thresh = np.vectorize(threshold, otypes = [np.int])\n",
    "\n",
    "def createDataSet(paths):\n",
    "    x = list()\n",
    "    y = list()\n",
    "    \n",
    "    for path in tqdm.tqdm(paths):\n",
    "        mat = loadmat(path)\n",
    "        images = mat['images']\n",
    "        fluidTensor = mat['manualFluid1']\n",
    "        \n",
    "        images = np.transpose(images, (2,0,1)) / 255\n",
    "        images = np.resize(images, (images.shape[0], WIDTH, HEIGHT))\n",
    "        fluidArray = np.transpose(fluidTensor, (2,0,1))\n",
    "        fliudArray = thresh(fluidArray)\n",
    "        fludiArray = np.resize(fluidArray, (fluidArray.shape[0], WIDTHOUT, HEIGHTOUT))\n",
    "        \n",
    "        for index in indices:\n",
    "            x = x + [np.expand_dims(images[index], 0)]\n",
    "            y = y + [np.expand_dims(fludiArray[index], 0)]\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "trainX, trainY = createDataSet(dataPath[:9])\n",
    "valX, valY = createDataSet(dataPath[9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape, trainY.shape, valX.shape, valY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 18\n",
    "EPOCHS = 100\n",
    "THRESHOLD = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer, criterion, inputs, labels):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward, optimize, backward\n",
    "    outputs = unet(inputs)\n",
    "    outputs = outputs.permute(0, 2, 3, 1) #check this one, if possible remove it\n",
    "    labels = labels.resize(BATCHSIZE * WIDTHOUT * HEIGHTOUT) #change this one\n",
    "    outputs = outputs.resize(BATCHSIZE * WIDTHOUT * HEIGHTOUT, 2)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.01\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(unet.parameters(), lr = learningRate, momentum=0.99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationLoss(x_val, y_val):\n",
    "    x_val = torch.from_numpy(x_val).float()\n",
    "    y_val = torch.from_numpy(y_val).long()\n",
    "    \n",
    "    m = x_val.shape[0]\n",
    "    outputs = unet(x_val)\n",
    "    # outputs.shape =(batch_size, n_classes, img_cols, img_rows) \n",
    "    outputs = outputs.permute(0, 2, 3, 1)\n",
    "    # outputs.shape =(batch_size, img_cols, img_rows, n_classes) \n",
    "    outputs = outputs.resize(m*width_out*height_out, 2)\n",
    "    labels = y_val.resize(m*width_out*height_out)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    return loss.data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHES = trainX.shape[0] // BATCHSIZE\n",
    "unet = unet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(EPOCHS):\n",
    "    totalLoss = 0\n",
    "    print(i)\n",
    "    for batch in range(BATCHES):\n",
    "        \n",
    "        batchX = torch.from_numpy(trainX[batch * BATCHSIZE : (batch+1) * BATCHSIZE]).float()\n",
    "        batchY = torch.from_numpy(trainY[batch * BATCHSIZE : (batch+1) * BATCHSIZE]).long()\n",
    "        \n",
    "        batchX, batchY = batchX.cuda(), batchY.cuda()\n",
    "        batchLoss = train(optimizer, criterion, batchX, batchY)\n",
    "        totalLoss += batchLoss\n",
    "    if i%20 == 0:\n",
    "        print('Loss at epoch {} is {}'.format(i, totalLoss / BATCHES)) \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
